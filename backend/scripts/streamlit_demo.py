#!/usr/bin/env python3
"""
Interactive Streamlit Demo for Alzheimer's Voice Detection
Real-time audio recording, word-by-word analysis, and live dashboard
"""

import streamlit as st
import numpy as np
import pandas as pd
import librosa
import soundfile as sf
from pathlib import Path
import sys
import tempfile
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime
import json

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.services.audio_processor import AudioProcessor
from app.services.asr_service import ASRService
from app.services.disfluency_analyzer import DisfluencyAnalyzer
from app.services.lexical_semantic_analyzer import LexicalSemanticAnalyzer

# Page configuration
st.set_page_config(
    page_title="Alzheimer's Voice Detection",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        padding: 1rem 0;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        text-align: center;
    }
    .risk-low {
        background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
    }
    .risk-moderate {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
    }
    .risk-high {
        background: linear-gradient(135deg, #fa709a 0%, #fee140 100%);
    }
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    }
</style>
""", unsafe_allow_html=True)


class AlzheimerVoiceApp:
    """Main application class"""
    
    def __init__(self):
        self.audio_processor = None
        self.asr_service = None
        self.disfluency_analyzer = None
        self.lexical_analyzer = None
        
        self._initialize_services()
    
    def _initialize_services(self):
        """Initialize analysis services"""
        with st.spinner("üîÑ Initializing AI models..."):
            try:
                self.audio_processor = AudioProcessor()
                self.asr_service = ASRService()
                self.disfluency_analyzer = DisfluencyAnalyzer()
                self.lexical_analyzer = LexicalSemanticAnalyzer()
                st.success("‚úÖ Models loaded successfully!")
            except Exception as e:
                st.error(f"‚ùå Failed to load models: {str(e)}")
    
    def analyze_audio(self, audio_path: str) -> dict:
        """Complete audio analysis pipeline"""
        
        results = {
            'status': 'processing',
            'acoustic_features': {},
            'transcription': {},
            'disfluency_analysis': {},
            'lexical_analysis': {},
            'word_timeline': [],
            'risk_score': {}
        }
        
        try:
            # Progress tracking
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # 1. Audio processing
            status_text.text("üéµ Processing audio...")
            progress_bar.progress(20)
            acoustic_features = self.audio_processor.process_audio_file(audio_path)
            results['acoustic_features'] = acoustic_features
            
            # 2. Transcription
            status_text.text("üé§ Transcribing speech...")
            progress_bar.progress(40)
            transcription = self.asr_service.transcribe_audio(audio_path)
            results['transcription'] = transcription
            
            # 3. Disfluency analysis
            status_text.text("üîç Analyzing disfluencies...")
            progress_bar.progress(60)
            disfluency_analysis = self.disfluency_analyzer.analyze_disfluencies(transcription)
            results['disfluency_analysis'] = disfluency_analysis
            
            # 4. Lexical-semantic analysis
            status_text.text("üìù Analyzing language patterns...")
            progress_bar.progress(80)
            lexical_analysis = self.lexical_analyzer.analyze_lexical_semantic_features(transcription)
            results['lexical_analysis'] = lexical_analysis
            
            # 5. Generate risk score
            status_text.text("üß† Calculating risk score...")
            progress_bar.progress(90)
            risk_score = self._calculate_risk_score(acoustic_features, disfluency_analysis, lexical_analysis)
            results['risk_score'] = risk_score
            
            # 6. Word timeline
            results['word_timeline'] = transcription.get('word_timestamps', [])
            
            progress_bar.progress(100)
            status_text.text("‚úÖ Analysis complete!")
            results['status'] = 'complete'
            
        except Exception as e:
            st.error(f"Analysis failed: {str(e)}")
            results['status'] = 'error'
            results['error'] = str(e)
        
        return results
    
    def _calculate_risk_score(self, acoustic: dict, disfluency: dict, lexical: dict) -> dict:
        """Calculate Alzheimer's risk score"""
        
        scores = []
        indicators = []
        
        # Acoustic biomarkers
        pause_ratio = acoustic.get('pause_time_ratio', 0)
        if pause_ratio > 0.25:
            scores.append(0.7)
            indicators.append("Excessive pausing detected")
        else:
            scores.append(0.2)
        
        pitch_range = acoustic.get('pitch_range', 100)
        if pitch_range < 50:
            scores.append(0.6)
            indicators.append("Reduced pitch variability")
        else:
            scores.append(0.2)
        
        # Disfluency biomarkers
        filled_pause_rate = disfluency.get('filled_pause_rate', 0)
        if filled_pause_rate > 0.10:
            scores.append(0.6)
            indicators.append("Frequent filled pauses (um, uh)")
        else:
            scores.append(0.2)
        
        repetition_rate = disfluency.get('repetition_rate', 0)
        if repetition_rate > 0.05:
            scores.append(0.6)
            indicators.append("Word repetitions detected")
        else:
            scores.append(0.2)
        
        # Lexical biomarkers
        ttr = lexical.get('type_token_ratio', 0.7)
        if ttr < 0.60:
            scores.append(0.7)
            indicators.append("Reduced vocabulary diversity")
        else:
            scores.append(0.2)
        
        coherence = lexical.get('semantic_coherence_score', 0.7)
        if coherence < 0.5:
            scores.append(0.8)
            indicators.append("Low semantic coherence")
        else:
            scores.append(0.2)
        
        # Calculate overall score
        overall_score = np.mean(scores) if scores else 0.5
        
        # Determine risk category
        if overall_score < 0.3:
            risk_category = "Low Risk (Healthy)"
            risk_class = "low"
        elif overall_score < 0.6:
            risk_category = "Moderate Risk (Uncertain)"
            risk_class = "moderate"
        else:
            risk_category = "High Risk (Possible Alzheimer's)"
            risk_class = "high"
        
        return {
            'overall_score': overall_score,
            'risk_category': risk_category,
            'risk_class': risk_class,
            'indicators': indicators,
            'confidence': 0.75 + (len(scores) / 20)  # Higher confidence with more features
        }


def render_header():
    """Render application header"""
    st.markdown('<h1 class="main-header">üß† Alzheimer\'s Voice Detection System</h1>', unsafe_allow_html=True)
    st.markdown("""
    <p style="text-align: center; font-size: 1.2rem; color: #666;">
    Advanced AI-powered voice analysis for early Alzheimer's detection
    </p>
    """, unsafe_allow_html=True)
    st.markdown("---")


def render_sidebar():
    """Render sidebar with information"""
    with st.sidebar:
        st.image("https://img.icons8.com/fluency/96/brain.png", width=80)
        st.title("About")
        st.info("""
        This system analyzes voice recordings to detect potential signs of Alzheimer's disease using:
        
        - **Advanced Speech Understanding**: AI analyzes speech content without displaying text
        - **Acoustic Analysis**: Pitch, rhythm, voice quality patterns
        - **Speech Fluency**: Pauses, hesitations, word-finding difficulty
        - **Language Patterns**: Vocabulary richness, coherence, complexity
        - **Deep Learning**: Wav2Vec2 embeddings, semantic analysis
        """)
        
        st.warning("‚ö†Ô∏è **Disclaimer**: This tool is for research purposes only. Not for clinical diagnosis.")
        
        st.markdown("---")
        st.markdown("### üìä Analysis Features")
        st.markdown("""
        - **100+ biomarkers** analyzed per recording
        - **Word-level timing** and rhythm patterns
        - **Speech flow** characteristics
        - **Vocabulary richness** assessment
        - **Pause pattern** analysis
        - **Voice quality** metrics
        - **Semantic understanding** (no text display)
        """)


def render_risk_dashboard(risk_score: dict):
    """Render risk assessment dashboard"""
    st.markdown("### üéØ Risk Assessment")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        risk_class = risk_score['risk_class']
        st.markdown(f"""
        <div class="metric-card risk-{risk_class}">
            <h2>{risk_score['risk_category']}</h2>
            <h1>{risk_score['overall_score']:.1%}</h1>
            <p>Risk Probability</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <h2>Confidence</h2>
            <h1>{risk_score['confidence']:.1%}</h1>
            <p>Analysis Confidence</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="metric-card">
            <h2>Indicators</h2>
            <h1>{len(risk_score['indicators'])}</h1>
            <p>Risk Factors Found</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Risk indicators
    if risk_score['indicators']:
        st.markdown("#### üö® Risk Indicators Detected:")
        for indicator in risk_score['indicators']:
            st.warning(f"‚Ä¢ {indicator}")


def render_acoustic_features(acoustic: dict):
    """Render acoustic features visualization"""
    st.markdown("### üéµ Acoustic Features")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Pitch analysis
        fig_pitch = go.Figure()
        fig_pitch.add_trace(go.Indicator(
            mode="gauge+number",
            value=acoustic.get('pitch_mean', 0),
            title={'text': "Mean Pitch (Hz)"},
            gauge={
                'axis': {'range': [0, 300]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 100], 'color': "lightgray"},
                    {'range': [100, 200], 'color': "gray"},
                    {'range': [200, 300], 'color': "darkgray"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 150
                }
            }
        ))
        fig_pitch.update_layout(height=250)
        st.plotly_chart(fig_pitch, use_container_width=True)
    
    with col2:
        # Voice quality metrics
        metrics_data = {
            'Metric': ['Jitter', 'Shimmer', 'HNR', 'Pitch Std'],
            'Value': [
                acoustic.get('jitter_local', 0) * 100,
                acoustic.get('shimmer_local', 0) * 100,
                acoustic.get('hnr_mean', 0),
                acoustic.get('pitch_std', 0)
            ]
        }
        fig_metrics = px.bar(
            metrics_data,
            x='Metric',
            y='Value',
            title="Voice Quality Metrics",
            color='Value',
            color_continuous_scale='Viridis'
        )
        fig_metrics.update_layout(height=250)
        st.plotly_chart(fig_metrics, use_container_width=True)
    
    # Timing features
    col3, col4, col5 = st.columns(3)
    
    with col3:
        st.metric(
            "Speech Time Ratio",
            f"{acoustic.get('speech_time_ratio', 0):.1%}",
            delta=None
        )
    
    with col4:
        st.metric(
            "Pause Frequency",
            f"{acoustic.get('pause_frequency', 0):.1f}/min",
            delta=None
        )
    
    with col5:
        st.metric(
            "Mean Pause Duration",
            f"{acoustic.get('mean_pause_duration', 0):.2f}s",
            delta=None
        )


def render_speech_understanding(transcription: dict, lexical: dict):
    """Render advanced speech understanding analysis (without showing transcript)"""
    st.markdown("### üéØ Speech Understanding Analysis")
    
    # Extract speech metrics without showing text
    word_timestamps = transcription.get('word_timestamps', [])
    word_count = len(word_timestamps)
    
    # Calculate advanced speech metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "Words Spoken",
            word_count,
            delta=None,
            help="Total number of words detected in speech"
        )
    
    with col2:
        unique_words = lexical.get('unique_words', 0)
        st.metric(
            "Vocabulary Richness",
            f"{unique_words} unique",
            delta=None,
            help="Number of different words used"
        )
    
    with col3:
        avg_word_length = lexical.get('mean_word_length', 0)
        st.metric(
            "Avg Word Length",
            f"{avg_word_length:.1f} chars",
            delta=None,
            help="Average length of words used"
        )
    
    with col4:
        sentences = lexical.get('sentence_count', 0)
        st.metric(
            "Sentences",
            sentences,
            delta=None,
            help="Number of complete sentences detected"
        )
    
    # Speech rhythm visualization (without showing words)
    if word_timestamps:
        st.markdown("#### üéº Speech Rhythm Pattern")
        
        # Create rhythm visualization using word durations
        rhythm_data = []
        for i, word_info in enumerate(word_timestamps[:100]):  # Limit to first 100 words
            duration = word_info.get('end', 0) - word_info.get('start', 0)
            rhythm_data.append({
                'Position': i + 1,
                'Duration': duration * 1000,  # Convert to ms
                'Type': 'Word'
            })
            
            # Add pause if not last word
            if i < len(word_timestamps) - 1:
                next_word = word_timestamps[i + 1]
                pause = next_word.get('start', 0) - word_info.get('end', 0)
                if pause > 0.05:  # Only show pauses > 50ms
                    rhythm_data.append({
                        'Position': i + 1.5,
                        'Duration': pause * 1000,
                        'Type': 'Pause'
                    })
        
        df_rhythm = pd.DataFrame(rhythm_data)
        
        fig_rhythm = px.scatter(
            df_rhythm,
            x='Position',
            y='Duration',
            color='Type',
            title="Speech Rhythm: Word Durations and Pauses",
            labels={'Duration': 'Duration (ms)', 'Position': 'Sequence'},
            color_discrete_map={'Word': '#667eea', 'Pause': '#f5576c'}
        )
        fig_rhythm.update_layout(height=300)
        st.plotly_chart(fig_rhythm, use_container_width=True)
        
        # Speech flow analysis
        st.markdown("#### üåä Speech Flow Characteristics")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Word duration distribution
            word_durations = [w.get('end', 0) - w.get('start', 0) for w in word_timestamps]
            fig_dur = go.Figure(data=[go.Histogram(
                x=[d * 1000 for d in word_durations],
                nbinsx=20,
                marker_color='#667eea'
            )])
            fig_dur.update_layout(
                title="Word Duration Distribution",
                xaxis_title="Duration (ms)",
                yaxis_title="Frequency",
                height=250
            )
            st.plotly_chart(fig_dur, use_container_width=True)
        
        with col2:
            # Pause pattern analysis
            pauses = []
            for i in range(len(word_timestamps) - 1):
                pause = word_timestamps[i+1].get('start', 0) - word_timestamps[i].get('end', 0)
                if pause > 0:
                    pauses.append(pause)
            
            if pauses:
                fig_pause = go.Figure(data=[go.Histogram(
                    x=[p * 1000 for p in pauses],
                    nbinsx=20,
                    marker_color='#f5576c'
                )])
                fig_pause.update_layout(
                    title="Pause Duration Distribution",
                    xaxis_title="Pause Duration (ms)",
                    yaxis_title="Frequency",
                    height=250
                )
                st.plotly_chart(fig_pause, use_container_width=True)


def render_disfluency_analysis(disfluency: dict):
    """Render disfluency analysis"""
    st.markdown("### üîç Disfluency Analysis")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "Filled Pauses",
            disfluency.get('filled_pauses_count', 0),
            delta=None
        )
    
    with col2:
        st.metric(
            "Repetitions",
            disfluency.get('repetitions_count', 0),
            delta=None
        )
    
    with col3:
        st.metric(
            "False Starts",
            disfluency.get('false_starts_count', 0),
            delta=None
        )
    
    with col4:
        st.metric(
            "Total Disfluency Rate",
            f"{disfluency.get('total_disfluency_rate', 0):.1%}",
            delta=None
        )
    
    # Disfluency events timeline
    disfluency_events = disfluency.get('disfluency_events', [])
    
    if disfluency_events:
        st.markdown("#### üìä Disfluency Events")
        
        events_data = []
        for event in disfluency_events[:20]:  # Limit to 20 events
            events_data.append({
                'Type': event.get('type', 'unknown'),
                'Text': event.get('text', ''),
                'Time': event.get('start_time', 0)
            })
        
        df_events = pd.DataFrame(events_data)
        st.dataframe(df_events, use_container_width=True)


def render_lexical_analysis(lexical: dict):
    """Render lexical-semantic analysis"""
    st.markdown("### üìö Lexical-Semantic Analysis")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            "Total Words",
            lexical.get('total_words', 0),
            delta=None
        )
        st.metric(
            "Unique Words",
            lexical.get('unique_words', 0),
            delta=None
        )
    
    with col2:
        st.metric(
            "Type-Token Ratio",
            f"{lexical.get('type_token_ratio', 0):.2f}",
            delta=None
        )
        st.metric(
            "Semantic Coherence",
            f"{lexical.get('semantic_coherence_score', 0):.2f}",
            delta=None
        )
    
    with col3:
        st.metric(
            "Mean Sentence Length",
            f"{lexical.get('mean_sentence_length', 0):.1f}",
            delta=None
        )
        st.metric(
            "Idea Density",
            f"{lexical.get('idea_density', 0):.2f}",
            delta=None
        )


def main():
    """Main application"""
    
    # Initialize app
    if 'app' not in st.session_state:
        st.session_state.app = AlzheimerVoiceApp()
    
    app = st.session_state.app
    
    # Render UI
    render_header()
    render_sidebar()
    
    # Main content
    tab1, tab2, tab3 = st.tabs(["üì§ Upload Audio", "üéôÔ∏è Record Audio", "üìä Batch Analysis"])
    
    with tab1:
        st.markdown("### Upload Audio File")
        st.info("Upload a voice recording (WAV, MP3, M4A, OGG) for analysis")
        
        uploaded_file = st.file_uploader(
            "Choose an audio file",
            type=['wav', 'mp3', 'm4a', 'ogg'],
            help="Upload a voice recording for Alzheimer's risk assessment"
        )
        
        if uploaded_file is not None:
            # Save uploaded file
            with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                tmp_file.write(uploaded_file.read())
                audio_path = tmp_file.name
            
            # Display audio player
            st.audio(uploaded_file, format=f'audio/{Path(uploaded_file.name).suffix[1:]}')
            
            # Analyze button
            if st.button("üî¨ Analyze Audio", type="primary"):
                with st.spinner("Analyzing audio..."):
                    results = app.analyze_audio(audio_path)
                
                if results['status'] == 'complete':
                    # Display results
                    st.success("‚úÖ Analysis Complete!")
                    
                    # Risk dashboard
                    render_risk_dashboard(results['risk_score'])
                    
                    st.markdown("---")
                    
                    # Detailed analysis tabs
                    detail_tab1, detail_tab2, detail_tab3, detail_tab4 = st.tabs([
                        "üéµ Acoustic", "üéØ Speech Understanding", "üîç Disfluency", "üìö Language Patterns"
                    ])
                    
                    with detail_tab1:
                        render_acoustic_features(results['acoustic_features'])
                    
                    with detail_tab2:
                        render_speech_understanding(results['transcription'], results['lexical_analysis'])
                    
                    with detail_tab3:
                        render_disfluency_analysis(results['disfluency_analysis'])
                    
                    with detail_tab4:
                        render_lexical_analysis(results['lexical_analysis'])
                    
                    # Download results
                    st.markdown("---")
                    st.markdown("### üíæ Download Results")
                    
                    results_json = json.dumps(results, indent=2, default=str)
                    st.download_button(
                        label="Download Full Analysis (JSON)",
                        data=results_json,
                        file_name=f"alzheimer_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json"
                    )
    
    with tab2:
        st.markdown("### Record Audio")
        st.info("üéôÔ∏è Real-time recording feature coming soon!")
        st.markdown("""
        This feature will allow you to:
        - Record audio directly in the browser
        - See live waveform visualization
        - Get real-time analysis as you speak
        - Monitor speech quality indicators
        """)
    
    with tab3:
        st.markdown("### Batch Analysis")
        st.info("üìä Batch processing feature coming soon!")
        st.markdown("""
        This feature will allow you to:
        - Upload multiple audio files at once
        - Process them in parallel
        - Compare results across recordings
        - Export comprehensive reports
        """)


if __name__ == "__main__":
    main()
